{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**DEVELOPING A CHAT ASSISTANT USING RETRIEVAL AUGMENTED GENERATION (RAG)**"
      ],
      "metadata": {
        "id": "aOw9-gE9GBmd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Overview:**\n",
        "\n",
        "This Jupyter Notebook demonstrates the implementation of a Retrieval Augmented Generation (RAG) chat assistant using:\n",
        "\n",
        "- LangChain for document processing and retrieval,\n",
        "\n",
        "- Hugging Face Embeddings for text vectorization,\n",
        "\n",
        "- Chroma Vector Database for document storage,\n",
        "\n",
        "- Groq's LLM for generating responses,\n",
        "\n",
        "- Gradio for creating an interactive web interface\n",
        "\n",
        "Key Components:\n",
        "\n",
        "- Document Loading,\n",
        "\n",
        "- Text Splitting,\n",
        "\n",
        "- Embedding Generation,\n",
        "\n",
        "- Vector Database Creation,\n",
        "\n",
        "- Conversational Retrieval Chain,\n",
        "\n",
        "- Gradio Interface"
      ],
      "metadata": {
        "id": "YCGy53K_Zo3Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 1: Library Installation**\n",
        "\n",
        "Install the required libraries for our RAG chat assistant. Note the specific versions to ensure compatibility."
      ],
      "metadata": {
        "id": "UiRsaFF6azlB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "CwH1D_Y77lrn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "c507f4a3-a882-4bda-b8e7-981826947549"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: chromadb==0.5.5 in /usr/local/lib/python3.10/dist-packages (0.5.5)\n",
            "Requirement already satisfied: langchain-chroma==0.1.2 in /usr/local/lib/python3.10/dist-packages (0.1.2)\n",
            "Requirement already satisfied: langchain==0.2.11 in /usr/local/lib/python3.10/dist-packages (0.2.11)\n",
            "Requirement already satisfied: langchain-community==0.2.10 in /usr/local/lib/python3.10/dist-packages (0.2.10)\n",
            "Requirement already satisfied: langchain-text-splitters==0.2.2 in /usr/local/lib/python3.10/dist-packages (0.2.2)\n",
            "Requirement already satisfied: langchain-groq==0.1.6 in /usr/local/lib/python3.10/dist-packages (0.1.6)\n",
            "Requirement already satisfied: transformers==4.43.2 in /usr/local/lib/python3.10/dist-packages (4.43.2)\n",
            "Requirement already satisfied: sentence-transformers==3.0.1 in /usr/local/lib/python3.10/dist-packages (3.0.1)\n",
            "Requirement already satisfied: unstructured==0.15.0 in /usr/local/lib/python3.10/dist-packages (0.15.0)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.10/dist-packages (5.8.0)\n",
            "Requirement already satisfied: pydantic-settings in /usr/local/lib/python3.10/dist-packages (2.6.1)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.5.5) (1.2.2.post1)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.5.5) (2.9.2)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.6 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.5.5) (0.7.6)\n",
            "Requirement already satisfied: fastapi>=0.95.2 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.5.5) (0.115.6)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==0.5.5) (0.32.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.22.5 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.5.5) (1.26.4)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.5.5) (3.7.4)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.5.5) (4.12.2)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.5.5) (1.20.1)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.5.5) (1.28.2)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.5.5) (1.28.2)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.5.5) (0.49b2)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.5.5) (1.28.2)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.5.5) (0.19.1)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.5.5) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.5.5) (4.66.6)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.5.5) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb==0.5.5) (6.4.5)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.5.5) (1.68.0)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.5.5) (4.2.1)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.5.5) (0.13.0)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.5.5) (31.0.0)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.5.5) (8.5.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.5.5) (6.0.2)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.5.5) (5.0.1)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.5.5) (3.10.11)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.5.5) (0.27.2)\n",
            "Requirement already satisfied: langchain-core<0.3,>=0.1.40 in /usr/local/lib/python3.10/dist-packages (from langchain-chroma==0.1.2) (0.2.43)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.2.11) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.2.11) (3.11.2)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.2.11) (4.0.3)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain==0.2.11) (0.1.143)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain==0.2.11) (2.32.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community==0.2.10) (0.6.7)\n",
            "Requirement already satisfied: groq<1,>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain-groq==0.1.6) (0.13.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.43.2) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers==4.43.2) (0.26.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.43.2) (24.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.43.2) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.43.2) (0.4.5)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==3.0.1) (2.5.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==3.0.1) (1.5.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==3.0.1) (1.13.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==3.0.1) (11.0.0)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from unstructured==0.15.0) (5.2.0)\n",
            "Requirement already satisfied: filetype in /usr/local/lib/python3.10/dist-packages (from unstructured==0.15.0) (1.2.0)\n",
            "Requirement already satisfied: python-magic in /usr/local/lib/python3.10/dist-packages (from unstructured==0.15.0) (0.4.27)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from unstructured==0.15.0) (5.3.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from unstructured==0.15.0) (3.9.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from unstructured==0.15.0) (0.9.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from unstructured==0.15.0) (4.12.3)\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.10/dist-packages (from unstructured==0.15.0) (2.14.0)\n",
            "Requirement already satisfied: python-iso639 in /usr/local/lib/python3.10/dist-packages (from unstructured==0.15.0) (2024.10.22)\n",
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.10/dist-packages (from unstructured==0.15.0) (1.0.9)\n",
            "Requirement already satisfied: rapidfuzz in /usr/local/lib/python3.10/dist-packages (from unstructured==0.15.0) (3.10.1)\n",
            "Requirement already satisfied: backoff in /usr/local/lib/python3.10/dist-packages (from unstructured==0.15.0) (2.2.1)\n",
            "Requirement already satisfied: unstructured-client in /usr/local/lib/python3.10/dist-packages (from unstructured==0.15.0) (0.27.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from unstructured==0.15.0) (1.16.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from unstructured==0.15.0) (5.9.5)\n",
            "Requirement already satisfied: onnx in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]==0.15.0) (1.17.0)\n",
            "Requirement already satisfied: pdf2image in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]==0.15.0) (1.17.0)\n",
            "Requirement already satisfied: pdfminer.six in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]==0.15.0) (20231228)\n",
            "Requirement already satisfied: pikepdf in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]==0.15.0) (9.4.2)\n",
            "Requirement already satisfied: pillow-heif in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]==0.15.0) (0.21.0)\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]==0.15.0) (5.1.0)\n",
            "Requirement already satisfied: pytesseract in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]==0.15.0) (0.3.13)\n",
            "Requirement already satisfied: google-cloud-vision in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]==0.15.0) (3.8.1)\n",
            "Requirement already satisfied: effdet in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]==0.15.0) (0.4.1)\n",
            "Requirement already satisfied: unstructured-inference==0.7.36 in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]==0.15.0) (0.7.36)\n",
            "Requirement already satisfied: unstructured.pytesseract>=0.3.12 in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]==0.15.0) (0.3.13)\n",
            "Requirement already satisfied: layoutparser in /usr/local/lib/python3.10/dist-packages (from unstructured-inference==0.7.36->unstructured[pdf]==0.15.0) (0.3.4)\n",
            "Requirement already satisfied: python-multipart in /usr/local/lib/python3.10/dist-packages (from unstructured-inference==0.7.36->unstructured[pdf]==0.15.0) (0.0.19)\n",
            "Requirement already satisfied: opencv-python!=4.7.0.68 in /usr/local/lib/python3.10/dist-packages (from unstructured-inference==0.7.36->unstructured[pdf]==0.15.0) (4.10.0.84)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from unstructured-inference==0.7.36->unstructured[pdf]==0.15.0) (3.8.0)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.10/dist-packages (from unstructured-inference==0.7.36->unstructured[pdf]==0.15.0) (1.0.11)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio) (0.4.0)\n",
            "Requirement already satisfied: gradio-client==1.5.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.5.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.8.1)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.41.3)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.13.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.5.1->gradio) (2024.10.0)\n",
            "Requirement already satisfied: websockets<15.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.5.1->gradio) (14.1)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-settings) (1.0.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.11) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.11) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.11) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.11) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.11) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.11) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.11) (1.17.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb==0.5.5) (1.2.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb==0.5.5) (2.1.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.2.10) (3.23.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.2.10) (0.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain-groq==0.1.6) (1.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb==0.5.5) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb==0.5.5) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb==0.5.5) (0.14.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb==0.5.5) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb==0.5.5) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb==0.5.5) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb==0.5.5) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb==0.5.5) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb==0.5.5) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb==0.5.5) (2.2.3)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb==0.5.5) (0.9)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.40->langchain-chroma==0.1.2) (1.33)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.2.11) (1.0.0)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb==0.5.5) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb==0.5.5) (24.3.25)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb==0.5.5) (5.29.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb==0.5.5) (1.13.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb==0.5.5) (1.2.15)\n",
            "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb==0.5.5) (8.5.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.5.5) (1.66.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.28.2 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.5.5) (1.28.2)\n",
            "Requirement already satisfied: opentelemetry-proto==1.28.2 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.5.5) (1.28.2)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.49b2 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.5.5) (0.49b2)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.49b2 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.5.5) (0.49b2)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.49b2 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.5.5) (0.49b2)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.49b2 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.5.5) (0.49b2)\n",
            "Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-asgi==0.49b2->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.5.5) (3.8.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb==0.5.5) (1.6)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb==0.5.5) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb==0.5.5) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.2.11) (3.4.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.2.11) (3.1.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers==3.0.1) (3.4.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb==0.5.5) (1.3.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb==0.5.5) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb==0.5.5) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb==0.5.5) (13.9.4)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==0.5.5) (0.6.4)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==0.5.5) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==0.5.5) (1.0.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->unstructured==0.15.0) (2.6)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from effdet->unstructured[pdf]==0.15.0) (0.20.1+cu121)\n",
            "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from effdet->unstructured[pdf]==0.15.0) (2.0.8)\n",
            "Requirement already satisfied: omegaconf>=2.0 in /usr/local/lib/python3.10/dist-packages (from effdet->unstructured[pdf]==0.15.0) (2.3.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision->unstructured[pdf]==0.15.0) (2.19.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-vision->unstructured[pdf]==0.15.0) (1.25.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured==0.15.0) (1.4.2)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six->unstructured[pdf]==0.15.0) (43.0.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers==3.0.1) (3.5.0)\n",
            "Requirement already satisfied: eval-type-backport<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured==0.15.0) (0.2.0)\n",
            "Requirement already satisfied: jsonpath-python<2.0.0,>=1.0.6 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured==0.15.0) (1.0.6)\n",
            "Requirement already satisfied: nest-asyncio>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured==0.15.0) (1.6.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six->unstructured[pdf]==0.15.0) (1.17.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision->unstructured[pdf]==0.15.0) (1.62.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.5.5) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.5.5) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.5.5) (4.9)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb==0.5.5) (3.21.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.1.40->langchain-chroma==0.1.2) (3.0.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.10/dist-packages (from omegaconf>=2.0->effdet->unstructured[pdf]==0.15.0) (4.9.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->unstructured-inference==0.7.36->unstructured[pdf]==0.15.0) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->unstructured-inference==0.7.36->unstructured[pdf]==0.15.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->unstructured-inference==0.7.36->unstructured[pdf]==0.15.0) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->unstructured-inference==0.7.36->unstructured[pdf]==0.15.0) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->unstructured-inference==0.7.36->unstructured[pdf]==0.15.0) (3.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.9.0->chromadb==0.5.5) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.9.0->chromadb==0.5.5) (2.18.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community==0.2.10) (1.0.0)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb==0.5.5) (10.0)\n",
            "Requirement already satisfied: iopath in /usr/local/lib/python3.10/dist-packages (from layoutparser->unstructured-inference==0.7.36->unstructured[pdf]==0.15.0) (0.1.10)\n",
            "Requirement already satisfied: pdfplumber in /usr/local/lib/python3.10/dist-packages (from layoutparser->unstructured-inference==0.7.36->unstructured[pdf]==0.15.0) (0.11.4)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six->unstructured[pdf]==0.15.0) (2.22)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.9.0->chromadb==0.5.5) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.5.5) (0.6.1)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from iopath->layoutparser->unstructured-inference==0.7.36->unstructured[pdf]==0.15.0) (3.0.0)\n",
            "Requirement already satisfied: pypdfium2>=4.18.0 in /usr/local/lib/python3.10/dist-packages (from pdfplumber->layoutparser->unstructured-inference==0.7.36->unstructured[pdf]==0.15.0) (4.30.0)\n"
          ]
        }
      ],
      "source": [
        "# Install relevant libraries with specific versions\n",
        "!pip install chromadb==0.5.5 langchain-chroma==0.1.2 langchain==0.2.11 langchain-community==0.2.10 langchain-text-splitters==0.2.2 langchain-groq==0.1.6 transformers==4.43.2 sentence-transformers==3.0.1 unstructured==0.15.0 unstructured[pdf]==0.15.0 gradio pydantic-settings"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 2: Import Required Libraries**\n",
        "\n",
        "Import the necessary Python and LangChain libraries for our RAG chat assistant. We'll use:\n",
        "\n",
        "- Standard Python libraries for timing and text processing,\n",
        "\n",
        "- Gradio for web interface,\n",
        "\n",
        "- LangChain components for document loading, text splitting, embedding, and retrieval"
      ],
      "metadata": {
        "id": "OISlQjZfbZx9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import relevant libraries\n",
        "\n",
        "import time\n",
        "import textwrap\n",
        "import gradio as gr\n",
        "\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_text_splitters import CharacterTextSplitter\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "\n",
        "from config import settings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "ca_NF_vOENwJ"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 3: API Key Configuration**\n",
        "\n",
        "Retrieve the Groq API key from the configuration settings. It's crucial to keep API keys secure and not hardcode them in the notebook.\n",
        "\n",
        "**NOTE:**\n",
        "\n",
        "If you do not have a groq api key, please visit [the link](https://console.groq.com/login) to signup and get your API key."
      ],
      "metadata": {
        "id": "aweV7Dhtb01N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve Groq API key from the `config` python script\n",
        "# Assign the retrieved key to a variable\n",
        "groq_api_key = settings.groq_api_key"
      ],
      "metadata": {
        "id": "zdf_IO3pIpGE"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 4: Document Loading**\n",
        "\n",
        "Load PDF documents from specified file paths. This example uses multiple documents.\n",
        "The PDF documents will be what our chat assistant will use in retrieving information.\n",
        "\n",
        "**Note:**\n",
        "\n",
        "- Adjust file paths according to your document locations.\n",
        "\n",
        "- `PyPDFLoader` supports multiple document types."
      ],
      "metadata": {
        "id": "M_zAxHiadsIB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define file paths for documents to be loaded\n",
        "file_path = [\n",
        "    \"/content/A_B Testing Explained.pdf\",\n",
        "    \"/content/NigeriaDataProtectionRegulation11.pdf\",\n",
        "    \"/content/Explore a strategy for sustained employee and organizational Performance.pdf\",\n",
        "    \"/content/Chapter 4 Exploratory Data Analysis.pdf\"\n",
        "]\n",
        "\n",
        "# Initialize a list to store loaded documents\n",
        "documents = []\n",
        "\n",
        "# Iterate through each file path,\n",
        "# load the documents using PyPDFLoader\n",
        "# append contents in `documents` list\n",
        "for path in file_path:\n",
        "    loader = PyPDFLoader(path)\n",
        "    doc = loader.load()\n",
        "    documents.append(doc)"
      ],
      "metadata": {
        "id": "02jESUKYI8q7"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preview the first document in the `documents` list\n",
        "documents[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkFo_M4nQlEa",
        "outputId": "2f881d80-9b98-4455-9c12-e1c6131abe20"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': '/content/A_B Testing Explained.pdf', 'page': 0}, page_content='A/BTESTING\\nA/Btesting, also known as split testing, isasimpleyet powerfulmethod used to compare two versions of a product, webpage, orfeaturetodeterminewhichoneperformsbetter.It\\'swidelyusedinmarketing, product development, and UX design to makedata-drivendecisions.\\nHowA/BTestingWorks1. Formulate a Hypothesis: Start by identifying what youwant to improve. For example, you might hypothesize thatchanging the color of a \"BuyNow\"buttonwill increasetheconversionrate.2. Create Variants: Develop two versions of the item youwanttotest:a. A(Control):Thisistheoriginalversion.b. B (Treatment/Variant): This is the modified versionthatincludesthechangeyou\\'retesting.3. Divide the Audience: Randomly split your audience intotwogroups:a. GroupA:Seesthecontrolversion.b. GroupB:Seesthevariantversion.4. Run the Test: Both groups interact with their respectiveversions, and data is collected on how they perform. Thiscould be clicks, sign-ups, purchases, or any other metricrelevanttoyourgoal.5. Analyze Results: Compare the performance of the twoversions. If thevariant (B) performssignificantlybetterthan'),\n",
              " Document(metadata={'source': '/content/A_B Testing Explained.pdf', 'page': 1}, page_content=\"the control (A), you can conclude that the change had apositiveimpact.6. Make a Decision: Based on the results, decide whether toimplement the change across your entire audience or stickwiththeoriginalversion.\\nPerformingaStatisticalTestinA/BTesting\\nOnce you've collected data from your A/B test, you need toperformastatisticaltesttodetermineifthedifferencebetweenthecontrol and variant is significant. The most common test used isthe t-test for comparing means or the chi-square test forcomparingproportions.\\nHere’showyoucanperformandinterpret astatistical test inA/Btesting:\\nStep1:SetUpHypothesesIn general, a hypothesis simply means an educated guess orprediction. Ahypothesismust beatestablestatement;somethingthat you can support or falsify with observable evidence. Theobjectiveofahypothesisisforanideatobetested,notproveni.e.hypothesesaretoolsfor testingideasinastructuredway,withtheunderstanding that they are subject to change or rejection basedon the evidence collected. In an experiment, hypotheses are of 2types;NullHypothesisandAlternativeHypothesis.\\nNull Hypothesis (H ₀ ): There is no difference between the twoversions.Anyobserveddifferenceisduetorandomchance.\"),\n",
              " Document(metadata={'source': '/content/A_B Testing Explained.pdf', 'page': 2}, page_content=\"Alternative Hypothesis (H ₁ ): There is a significant differencebetweenthetwoversions.\\nStep2:ChoosetheAppropriateTestWhenconductinganA/Btest, choosingtheright statistical testiscrucial for accurately determining whether the differencesobserved between the control (A) and variant (B) groups arestatistically significant. The choice of test dependslargelyonthetype of data you're working with and the nature of the metricsyou'recomparing.\\ni. t-Test(IndependentSamplest-Test)\\nWhentoUse:Useat-test whenyouwanttocomparethemeans(averages)of a continuous variable between two independent groups.This test is appropriate if your metric is a numerical value,such as average time spent onawebpage, averagepurchasevalue,oraveragerevenueperuser.Assumptions:● Thedatashouldbenormallydistributed.● The variances of the two groups should be equal (thiscanbecheckedwithatestlikeLevene'stest).● Thetwogroupsshouldbeindependentofeachother.\\nExample:Suppose you’re testing whether a new webpage design(Treatment/Variant) leads to a higher average sessionduration compared to the old design (Control). You would\"),\n",
              " Document(metadata={'source': '/content/A_B Testing Explained.pdf', 'page': 3}, page_content='useat-test tocomparetheaveragesessiondurationbetweenthetwogroups.\\nii. Chi-SquareTest:\\nWhentoUse:Use a chi-square test when you want to compare theproportions or categorical outcomes between two groups.This is commonly used when your metric is binary orcategorical, such as conversion rate (e.g., did the userpurchaseornot),click-throughrate,orsign-uprate.Assumptions:● Theobservationsshouldbeindependent.● Theexpectedfrequencycountforeachcategoryshouldbeatleast5.\\nExample:If you’retestingwhetherchangingthecolorofa\"BuyNow\"button (Treatment/Variant) increases the conversion ratecompared to the original color (Control), you would use achi-squaretest.\\niii. z-Test(Proportionz-Test)\\nWhentoUse:Use a z-test when you want to compare the proportionsbetween two large independent groups. Like the chi-squaretest, thisisalsousedfor categorical data, but it isespeciallyusefulwhendealingwithlargesamplesizes.'),\n",
              " Document(metadata={'source': '/content/A_B Testing Explained.pdf', 'page': 4}, page_content='Assumptions:● Thesamplesizeshouldbelargeenoughfor thenormalapproximation to be valid (usually both groups shouldhaveatleast30observations).● Theobservationsshouldbeindependent.\\nExample:You could use a z-test to compare the proportion of userswho clicked on a call-to-action button between the controlandvariantgroupswhenyouhavealargenumberofusersineachgroup.\\nStep3:Calculatethep-valueThe p-value tells you theprobabilitythat theobserveddifferenceisduetochance.● Lowp-value(<0.05): Rejectthenullhypothesis,indicatingthatthedifferenceisstatisticallysignificant.● High p-value (> 0.05): Fail to reject the null hypothesis,indicatingthatthedifferenceisnotstatisticallysignificant.\\nNOTE: In hypothesis testing, you can never accept anyhypothesis (Null or Alternative). The final verdict on ahypothesiscaneitherbe“Reject”or“Failtoreject”.'),\n",
              " Document(metadata={'source': '/content/A_B Testing Explained.pdf', 'page': 5}, page_content='Step4:CheckforConfidenceInterval(Optional)This range estimates where the true difference between the twoversions lies. If the confidence interval does not include 0 (for adifferenceof means) or 1(for aratioof proportions), theresult isconsideredstatisticallysignificant.\\nStep5:InterprettheResult● If you reject the null hypothesis (with a lowp-value), youcan confidently say that the change you made had asignificanteffect.● If youfail toreject thenullhypothesis(withahighp-value),the change likely had no significant impact, and anyobserveddifferencecouldbeduetorandomvariation.\\nExamplePerformingaStatisticalTestinA/BTestingImagine you ran an A/Btest to see if changing the \"Buy Now\"button color from blue (Control) to green (Treatment/Variant)wouldincreasethepurchaserate.\\nStep1:SetUpHypothesesNull Hypothesis (H ₀ ): The green button does not affect thepurchaserate.Alternative Hypothesis (H ₁ ): The green button increases thepurchaserate.Step2:ChoosetheAppropriateTestYouchooseachi-squaretestStep3:Calculatethep-valueAfterperformingthetest,youobtainap-valueof0.03.'),\n",
              " Document(metadata={'source': '/content/A_B Testing Explained.pdf', 'page': 6}, page_content=\"Step5:InterprettheResultSince the p-value is below0.05, you reject the null hypothesis.This suggests that the green button has a statistically significantimpactonthepurchaserate.\\nKeyConceptsinA/BTesting\\ni. Statistical Significance: This measures the likelihood thattheresultsobservedarenotduetochance.Acommonthresholdis95% confidence, meaning there's only a 5% chance that theresultsarerandom.\\nii. Sample Size: To achieve reliable results, your test needstobe conducted on a sufficiently large sample. Too small a samplesizemayleadtoinaccurateconclusions.\\niii. Conversion Rate: This is the percentage of users whocompletethedesiredaction, suchasclickingabuttonormakingapurchase.ThegoalofA/Btestingisoftentoincreasethisrate.\\niv. ControlandExperimentalGroups:Thecontrolgroupseesthe original version, while the experimental group(Treatment/Variation) sees the newversion. Randomassignmenthelps ensure that any differences in outcomes are due to thechangesmade,nototherfactors.\"),\n",
              " Document(metadata={'source': '/content/A_B Testing Explained.pdf', 'page': 7}, page_content='BenefitsofA/BTesting\\n● Data-Driven Decisions: A/B testing removes guesswork,allowingdecisionstobebasedonactualdata.● Optimization: It helps optimize user experience andincreaseconversionsbyidentifyingwhatworksbest.● Cost-Effective: Implementing successful changesidentifiedthrough A/B testing can lead to significant improvementswithoutmajorinvestments.\\nCommonMistakestoAvoid\\n● TestingTooManyChangesat Once: Focusononechangeatatimetoclearlyunderstanditsimpact.● Stopping the Test Too Early: Ensure the test runs longenoughtogathersufficientdata.● Ignoring External Factors: Consider other variables, liketimeofdayorseason,thatmightaffecttheresults.\\nSUMMARY\\nInsummary, A/Btestingisastraightforwardandeffectivewaytomake informed decisions about changes to your product ormarketing strategy. By systematically comparing two versionsand analyzing the results, you can confidently choose the optionthatdeliversthebestoutcome.')]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 5: Text Chunking**\n",
        "\n",
        "Split documents into smaller, manageable text chunks to improve retrieval efficiency.\n",
        "\n",
        "**Chunking Parameters:**\n",
        "\n",
        "`chunk_size`: 1700 characters (adjust based on document complexity)\n",
        "\n",
        "`chunk_overlap`: 200 characters to maintain context between chunks"
      ],
      "metadata": {
        "id": "bA6i1jiDfLlh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize text splitter with specified chunk size and overlap\n",
        "text_splitter = CharacterTextSplitter(\n",
        "    chunk_size=1700,\n",
        "    chunk_overlap=200\n",
        ")"
      ],
      "metadata": {
        "id": "Yw7wd7mUOHfa"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split all documents into text chunks\n",
        "texts = []\n",
        "for doc in documents:\n",
        "    text_chunks = text_splitter.split_documents(doc)\n",
        "    texts.extend(text_chunks)"
      ],
      "metadata": {
        "id": "Sn84d1foPMo_"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preview the first text chunk\n",
        "print(texts[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "J0v8VJjUP1Lj",
        "outputId": "288ddda4-27a7-44e0-f10e-68aff75b4a37"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "page_content='A/BTESTING\n",
            "A/Btesting, also known as split testing, isasimpleyet powerfulmethod used to compare two versions of a product, webpage, orfeaturetodeterminewhichoneperformsbetter.It'swidelyusedinmarketing, product development, and UX design to makedata-drivendecisions.\n",
            "HowA/BTestingWorks1. Formulate a Hypothesis: Start by identifying what youwant to improve. For example, you might hypothesize thatchanging the color of a \"BuyNow\"buttonwill increasetheconversionrate.2. Create Variants: Develop two versions of the item youwanttotest:a. A(Control):Thisistheoriginalversion.b. B (Treatment/Variant): This is the modified versionthatincludesthechangeyou'retesting.3. Divide the Audience: Randomly split your audience intotwogroups:a. GroupA:Seesthecontrolversion.b. GroupB:Seesthevariantversion.4. Run the Test: Both groups interact with their respectiveversions, and data is collected on how they perform. Thiscould be clicks, sign-ups, purchases, or any other metricrelevanttoyourgoal.5. Analyze Results: Compare the performance of the twoversions. If thevariant (B) performssignificantlybetterthan' metadata={'source': '/content/A_B Testing Explained.pdf', 'page': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Code Explanation**\n",
        "\n",
        "The code above breaks down large documents into smaller, more manageable chunks. This technique, known as text chunking, enhances the efficiency of information retrieval systems (like our chat assistant).\n",
        "\n",
        "**Key Components:**\n",
        "\n",
        "`CharacterTextSplitter`: This method is specifically designed to split text into chunks based on character counts. It takes in several parameters but we'll use only 2;\n",
        "\n",
        "`chunk_size`: This parameter defines the maximum number of characters in a single chunk. In this case, it's set to 1700 characters. This size can be adjusted based on the complexity of the documents. For simpler texts, larger chunk sizes might be suitable, while more complex documents may benefit from smaller chunks.\n",
        "\n",
        "`chunk_overlap`: This parameter specifies the number of characters that overlap between consecutive chunks. In this case, 200 characters are overlapped. This overlap ensures that context is maintained across chunk boundaries, improving the quality of search results and analysis.\n",
        "\n",
        "**Text Chunking Process:**\n",
        "\n",
        "- Iterate over Documents: The `for` loop iterates over each document in the documents list.\n",
        "\n",
        "- Split Document: For each document, the text_splitter is used to divide the text into chunks of the specified size and overlap.\n",
        "\n",
        "- Append Chunks: The resulting chunks are appended to the texts list, creating a flattened list of all chunks from all documents.\n",
        "\n",
        "**Previewing the First Chunk:**\n",
        "\n",
        "The `print(texts[0])` line displays the content of the first chunk in the texts list. This provides a quick way to inspect the results of the chunking process.\n",
        "\n",
        "**Why Chunking?**\n",
        "\n",
        "- Improved Retrieval Efficiency: Smaller chunks can be indexed and searched more quickly than large documents.\n",
        "\n",
        "- Enhanced Contextual Understanding: The overlap between chunks helps maintain context, leading to more accurate search results.\n",
        "\n",
        "- Scalability: Chunking allows for efficient processing and storage of large document collections.\n",
        "\n",
        "- Flexibility: Chunks can be used for various tasks, such as summarization, translation, or sentiment analysis."
      ],
      "metadata": {
        "id": "t-H9iFknhyI0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 6: Embedding Generation and Vector db creation**\n",
        "\n",
        "Convert text chunks into vector embeddings using Hugging Face embeddings.\n",
        "\n",
        "**Process:**\n",
        "\n",
        "1. Create embeddings,\n",
        "\n",
        "2. Define persistent directory for vector database (optional)\n",
        "\n",
        "3. Create Chroma vector database"
      ],
      "metadata": {
        "id": "m4dNIrIPgAO9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Hugging Face embeddings\n",
        "embedding = HuggingFaceEmbeddings()\n",
        "\n",
        "# Set persistent directory for vector database storage\n",
        "persist_directory = \"/content/chroma_db\""
      ],
      "metadata": {
        "collapsed": true,
        "id": "YsCwQ0FYP5sg"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Chroma vector database with embedded documents\n",
        "vectordb = Chroma.from_documents(\n",
        "    documents=texts,\n",
        "    embedding=embedding,\n",
        "    persist_directory=persist_directory\n",
        ")"
      ],
      "metadata": {
        "id": "Q7iVunrdST26"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create retriever to fetch relevant document chunks\n",
        "retriever = vectordb.as_retriever()"
      ],
      "metadata": {
        "id": "r0TROIrwTbNN"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Code Explanation**\n",
        "\n",
        "The above code focuses on transforming text chunks into numerical representations (embeddings) and storing them in a vector database for efficient similarity search.\n",
        "\n",
        "**Key Components:**\n",
        "\n",
        "`HuggingFaceEmbeddings`: This is a pre-trained model from Hugging Face that can generate dense vector representations of text. When provided with text, it produces numerical vectors that capture semantic and syntactic information.\n",
        "\n",
        "`persist_directory`: The variable specifies the path to a directory where the vector database will be stored. This allows for persistent storage and retrieval of the database.\n",
        "\n",
        "`Chroma.from_documents`: The  function creates a Chroma vector database. It takes the texts i.e. the chunked documents, the embedding model, and the persist_directory as input.\n",
        "\n",
        "- Vector Storage: Chroma efficiently stores the text chunks along with their corresponding embeddings.\n",
        "\n",
        "- Similarity Search: This database is optimized for similarity search, enabling efficient retrieval of relevant documents based on semantic similarity.\n",
        "Retriever:\n",
        "\n",
        "Query Processing: The `retriever` object is created from the vector database. It can be used to process queries and return the most relevant document chunks based on semantic similarity.\n",
        "\n",
        "**Why Embeddings and Vector Databases?**\n",
        "\n",
        "- Semantic Search: Embeddings allow for more nuanced search, going beyond exact keyword matching.\n",
        "\n",
        "- Efficient Retrieval: Vector databases are highly optimized for similarity search, enabling fast retrieval of relevant documents.\n",
        "\n",
        "- Contextual Understanding: Embeddings capture the semantic and syntactic context of text, leading to more accurate and relevant search results.\n",
        "\n",
        "- Diverse Applications: This approach can be used for various tasks, including question answering, recommendation systems, and document summarization."
      ],
      "metadata": {
        "id": "38cINBz_kVKZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 7: Language Model Configuration**\n",
        "\n",
        "Set up the Groq Language Model (LLM) with specific parameters:\n",
        "\n",
        "- Model: Llama 3.1 70B Versatile,\n",
        "\n",
        "- Temperature: 0.5 (balanced creativity and consistency)\n",
        "\n",
        "**Note:**\n",
        "\n",
        "- Temperature controls randomness of responses\\,\n",
        "\n",
        "- Lower values make responses more focused and deterministic"
      ],
      "metadata": {
        "id": "VWJklBb1mawX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Groq Language Model\n",
        "llm = ChatGroq(\n",
        "    model=\"llama-3.1-70b-versatile\",\n",
        "    temperature=0.5,\n",
        "    groq_api_key=groq_api_key\n",
        ")"
      ],
      "metadata": {
        "id": "rV6TDoIFW0mi"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create conversational retrieval chain\n",
        "conv_chain = ConversationalRetrievalChain.from_llm(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=retriever,\n",
        "    return_source_documents=True\n",
        ")"
      ],
      "metadata": {
        "id": "apAzUfZhYEAo"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Code Explanation**\n",
        "\n",
        "The code sets up a language model and a conversational retrieval chain to enable more sophisticated and context-aware interactions with the user.\n",
        "\n",
        "**Key Components:**\n",
        "\n",
        "1. **Groq Language Model (LLM):**\n",
        "\n",
        "- **Model Selection:** The llama-3.1-70b-versatile model is chosen for its versatility and capability to handle a wide range of tasks.\n",
        "\n",
        "- **Temperature Setting:** The temperature parameter is set to 0.5. This balances creativity and consistency in the model's responses. A lower temperature results in more focused and deterministic outputs.\n",
        "\n",
        "2. **Conversational Retrieval Chain:**\n",
        "\n",
        "- **LLM Integration:** The ChatGroq LLM is integrated into the conversational retrieval chain.\n",
        "\n",
        "- **Chain Type:** The stuff chain type is used, where the entire document is fed into the LLM at once. This can be useful for more complex queries.\n",
        "\n",
        "- **Retriever Integration:** The retriever object, created earlier, is integrated into the chain. This allows the LLM to access relevant information from the vector database during the conversation.\n",
        "\n",
        "- **Source Document Return:** The return_source_documents parameter is set to True, allowing the chain to return the source documents that were used to generate the response. This can be helpful for fact-checking and transparency.\n",
        "\n",
        "**How it Works:**\n",
        "\n",
        "- User Query: A user poses a query.\n",
        "\n",
        "- Retrieval: The retriever searches the vector database for relevant document chunks based on semantic similarity.\n",
        "\n",
        "- LLM Processing: The LLM processes the query and the retrieved documents to generate a response.\n",
        "\n",
        "- Response Generation: The LLM leverages its knowledge and the retrieved information to formulate a comprehensive and informative response.\n",
        "\n",
        "- Response and Source Documents: The generated response and the source documents used to create the response are returned to the user."
      ],
      "metadata": {
        "id": "Dd10-9d8njVY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 8: Question Processing Function**\n",
        "\n",
        "Implement a robust function to process user questions with:\n",
        "\n",
        "- Error handling,\n",
        "\n",
        "- Response time tracking,\n",
        "\n",
        "- Chat history management\""
      ],
      "metadata": {
        "id": "75yEXwGPnG60"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Invoke the conversational chain to ask our question and get a response\n",
        "question = \"What is AB testing?\"\n",
        "response = conv_chain.invoke({\"question\": question, \"chat_history\": []})\n",
        "print(f\"Answer: {response['answer']}\")\n",
        "print(f\"Source Document: {response['source_documents']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hO_Kd6GNZAPI",
        "outputId": "26cfed6a-d8e9-49af-b737-956fc04f3621"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: A/B testing, also known as split testing, is a simple yet powerful method used to compare two versions of a product, webpage, or feature to determine which one performs better. It's widely used in marketing, product development, and UX design to make data-driven decisions.\n",
            "Source Document: [Document(metadata={'page': 7, 'source': '/content/A_B Testing Explained.pdf'}, page_content='BenefitsofA/BTesting\\n● Data-Driven Decisions: A/B testing removes guesswork,allowingdecisionstobebasedonactualdata.● Optimization: It helps optimize user experience andincreaseconversionsbyidentifyingwhatworksbest.● Cost-Effective: Implementing successful changesidentifiedthrough A/B testing can lead to significant improvementswithoutmajorinvestments.\\nCommonMistakestoAvoid\\n● TestingTooManyChangesat Once: Focusononechangeatatimetoclearlyunderstanditsimpact.● Stopping the Test Too Early: Ensure the test runs longenoughtogathersufficientdata.● Ignoring External Factors: Consider other variables, liketimeofdayorseason,thatmightaffecttheresults.\\nSUMMARY\\nInsummary, A/Btestingisastraightforwardandeffectivewaytomake informed decisions about changes to your product ormarketing strategy. By systematically comparing two versionsand analyzing the results, you can confidently choose the optionthatdeliversthebestoutcome.'), Document(metadata={'page': 7, 'source': '/content/A_B Testing Explained.pdf'}, page_content='BenefitsofA/BTesting\\n● Data-Driven Decisions: A/B testing removes guesswork,allowingdecisionstobebasedonactualdata.● Optimization: It helps optimize user experience andincreaseconversionsbyidentifyingwhatworksbest.● Cost-Effective: Implementing successful changesidentifiedthrough A/B testing can lead to significant improvementswithoutmajorinvestments.\\nCommonMistakestoAvoid\\n● TestingTooManyChangesat Once: Focusononechangeatatimetoclearlyunderstanditsimpact.● Stopping the Test Too Early: Ensure the test runs longenoughtogathersufficientdata.● Ignoring External Factors: Consider other variables, liketimeofdayorseason,thatmightaffecttheresults.\\nSUMMARY\\nInsummary, A/Btestingisastraightforwardandeffectivewaytomake informed decisions about changes to your product ormarketing strategy. By systematically comparing two versionsand analyzing the results, you can confidently choose the optionthatdeliversthebestoutcome.'), Document(metadata={'page': 0, 'source': '/content/A_B Testing Explained.pdf'}, page_content='A/BTESTING\\nA/Btesting, also known as split testing, isasimpleyet powerfulmethod used to compare two versions of a product, webpage, orfeaturetodeterminewhichoneperformsbetter.It\\'swidelyusedinmarketing, product development, and UX design to makedata-drivendecisions.\\nHowA/BTestingWorks1. Formulate a Hypothesis: Start by identifying what youwant to improve. For example, you might hypothesize thatchanging the color of a \"BuyNow\"buttonwill increasetheconversionrate.2. Create Variants: Develop two versions of the item youwanttotest:a. A(Control):Thisistheoriginalversion.b. B (Treatment/Variant): This is the modified versionthatincludesthechangeyou\\'retesting.3. Divide the Audience: Randomly split your audience intotwogroups:a. GroupA:Seesthecontrolversion.b. GroupB:Seesthevariantversion.4. Run the Test: Both groups interact with their respectiveversions, and data is collected on how they perform. Thiscould be clicks, sign-ups, purchases, or any other metricrelevanttoyourgoal.5. Analyze Results: Compare the performance of the twoversions. If thevariant (B) performssignificantlybetterthan'), Document(metadata={'page': 0, 'source': '/content/A_B Testing Explained.pdf'}, page_content='A/BTESTING\\nA/Btesting, also known as split testing, isasimpleyet powerfulmethod used to compare two versions of a product, webpage, orfeaturetodeterminewhichoneperformsbetter.It\\'swidelyusedinmarketing, product development, and UX design to makedata-drivendecisions.\\nHowA/BTestingWorks1. Formulate a Hypothesis: Start by identifying what youwant to improve. For example, you might hypothesize thatchanging the color of a \"BuyNow\"buttonwill increasetheconversionrate.2. Create Variants: Develop two versions of the item youwanttotest:a. A(Control):Thisistheoriginalversion.b. B (Treatment/Variant): This is the modified versionthatincludesthechangeyou\\'retesting.3. Divide the Audience: Randomly split your audience intotwogroups:a. GroupA:Seesthecontrolversion.b. GroupB:Seesthevariantversion.4. Run the Test: Both groups interact with their respectiveversions, and data is collected on how they perform. Thiscould be clicks, sign-ups, purchases, or any other metricrelevanttoyourgoal.5. Analyze Results: Compare the performance of the twoversions. If thevariant (B) performssignificantlybetterthan')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def process_question(user_question, history):\n",
        "    \"\"\"\n",
        "    Process a user's question and retrieve an answer using a conversational retrieval chain.\n",
        "\n",
        "    Args:\n",
        "        user_question (str): User's input question,\n",
        "        history (list): Previous conversation history\n",
        "\n",
        "    Returns:\n",
        "        tuple: Updated chat history and response\n",
        "    \"\"\"\n",
        "    try:\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Initialize empty history if None\n",
        "        if history is None:\n",
        "            history = []\n",
        "\n",
        "        # Prepare chat history for the retrieval chain\n",
        "        chat_history = [(h[0], h[1].split(\"\\n\\nResponse time:\")[0]) for h in history]\n",
        "\n",
        "        # Debug print\n",
        "        print(f\"Processing question: {user_question}\")\n",
        "        print(f\"Chat history: {chat_history}\")\n",
        "\n",
        "        # Invoke conversational chain with both the question and chat_history\n",
        "        response = conv_chain.invoke({\"question\": user_question, \"chat_history\": chat_history})\n",
        "\n",
        "        # If response is a dict, extract the actual response text\n",
        "        if isinstance(response, dict) and 'answer' in response:\n",
        "            response = response['answer']\n",
        "\n",
        "        # Measure the response time\n",
        "        end_time = time.time()\n",
        "        response_time = f\"Response time: {end_time - start_time:.2f} seconds.\"\n",
        "\n",
        "        # Combine the response and the response time\n",
        "        full_response = f\"{response}\\n\\n{response_time}\"\n",
        "\n",
        "        # Update the conversation history\n",
        "        history.append((user_question, full_response))\n",
        "\n",
        "        # Debug print\n",
        "        print(f\"Processed successfully. Response: {full_response}\")\n",
        "\n",
        "        return history, history, full_response\n",
        "\n",
        "    except Exception as e:\n",
        "        error_message = f\"An error occurred: {str(e)}\"\n",
        "        print(error_message)\n",
        "        return history, history, error_message\n",
        "\n"
      ],
      "metadata": {
        "id": "PYVBKE-jaBiI"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 9: Gradio Interface**\n",
        "\n",
        "Create an interactive web interface for the chat assistant using Gradio.\n",
        "\n",
        "Interface Features:\n",
        "\n",
        "- Text input for questions,\n",
        "\n",
        "- Chatbot conversation history,\n",
        "\n",
        "- Latest answer display"
      ],
      "metadata": {
        "id": "CcIo-GvXrI8i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup the Gradio interface for the chat assistant\n",
        "iface = gr.Interface(\n",
        "    fn=process_question,\n",
        "    inputs=[\n",
        "        gr.Textbox(lines=2, placeholder=\"Type your question here...\"),\n",
        "        gr.State()\n",
        "    ],\n",
        "    outputs=[\n",
        "        gr.Chatbot(),\n",
        "        gr.State(),\n",
        "        gr.Textbox(label=\"Latest Answer\")\n",
        "    ],\n",
        "    title=\"Chat Assistant\",\n",
        "    description=\"Ask any question about the document provided.\"\n",
        ")\n",
        "\n",
        "# Launch the interface\n",
        "iface.launch(share=True)\n",
        "\n",
        "\"\"\"\n",
        "Note: share=True enables public link generation\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "id": "vTmqEehfe_ce",
        "outputId": "c43e634b-18d6-41ca-fa4d-7d3c0ded372e"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://5ac638786de20827a4.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://5ac638786de20827a4.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nNote: share=True enables public link generation\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    }
  ]
}